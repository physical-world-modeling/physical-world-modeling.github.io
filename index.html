<!DOCTYPE html>
<html class="fontawesome-i2svg-active fontawesome-i2svg-complete">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta
      name="description"
      content="Building Physically Plausible World Models" />
    <meta name="keywords" content="World Models, Physics, Machine Learning" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="icon" type="image/png" href="data/images/favicon.png" />
    <meta
      property="og:image"
      content="https://physical-world-modeling.github.io/data/images/thumbnail.png" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Building Physically Plausible World Models</title>

    <meta
      name="twitter:image"
      content="https://physical-world-modeling.github.io/data/images/thumbnail.png" />

    <link rel="stylesheet" href="./data/bulma.min.css" />
    <link rel="stylesheet" href="./data/fontawesome.all.min.css" />
    <link rel="stylesheet" href="./data/academicons.min.css" />
    <link rel="stylesheet" href="./data/index.css" />
    <link rel="stylesheet" href="./data/style.css" />
    <script src="./data/modernizr.js"></script>
    <script src="./data/jquery.min.js"></script>
    <script defer src="./data/fontawesome.all.min.js"></script>

    <style>
      .page-header1 {
        position: relative;
        padding-bottom: 1rem;
        overflow: hidden;
      }

      .video-background {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        object-fit: cover;
        z-index: -1;
      }

      .overlay {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        background-color: rgba(0, 0, 0, 0.5);
        z-index: -1;
      }

      .hero-content {
        position: relative;
        z-index: 1;
      }

      .rcorners1 {
        border-radius: 10px;
        background: #ffffffd0;
        padding: 5px;
        font-size: 120%;
        color: #5c5c5c;
      }

      .button {
        border-radius: 10px;
        background: #ffffff;
        padding: 5px 15px 5px 15px;
      }

      /* Center crop profile images */
      .image.is-128x128 {
        overflow: hidden;
        position: relative;
      }

      .image.is-128x128 img {
        position: absolute;
        left: 50%;
        top: 50%;
        height: 100%;
        width: auto;
        transform: translate(-50%, -50%);
        min-width: 100%;
        min-height: 100%;
        object-fit: cover;
      }

      /* Center the image container itself */
      .image.is-128x128.mx-auto {
        margin: 0 auto;
        display: block;
      }

      .card-content.has-text-centered .image.is-128x128 {
        margin: 0 auto;
      }

      /* Mobile responsiveness for speaker cards */
      @media screen and (max-width: 768px) {
        .columns.is-vcentered {
          display: block;
        }
        .columns.is-vcentered .column {
          text-align: center;
          width: 100%;
        }
        .columns.is-vcentered .column.is-one-quarter {
          margin: 0 auto;
          max-width: 200px;
        }
        .columns.is-vcentered .column .image.is-128x128 {
          margin: 0 auto 1rem auto;
        }
      }
    </style>
  </head>

  <body>
    <section class="hero page-header1">
      <video class="video-background" autoplay muted loop playsinline>
        <source src="data/veo.mp4" type="video/mp4" />
      </video>
      <div class="overlay"></div>
      <div class="hero-body hero-content">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-2 publication-title" style="color: white">
                Building Physically Plausible World Models<br />
              </h1>
              <h1 class="is-is-5" style="color: white">
                <b>ICML 2025 Workshop, Vancouver</b>
              </h1>
              <h1 class="is-is-5" style="color: white">
                <b>Saturday, July 19 (Whole-Day Workshop)</b>
              </h1>
              <h1 class="is-is-5" style="color: white"><b>Room: Ballroom D, West Building</b></h1>
              <br />
            </div>
          </div>
        </div>

        <br />
        <br />
        <h2 class="subtitle has-text-centered">
          <a href="#schedule" class="button"><strong>Schedule</strong></a>
          <a href="#speakers" class="button"><strong>Speakers</strong></a>
          <a href="#call" class="button"><strong>Call For Papers</strong></a>
          <a href="#organizers" class="button"><strong>Organizers</strong></a>
        </h2>
      </div>
    </section>

    <section class="section" style="margin-top: -50px">
      <div class="container is-max-desktop">
        <section class="section" id="Motivation">
          <div class="container is-max-desktop content">
            <h2 class="title">Overview</h2>
            <div class="content has-text-justified">
              The goal of this workshop is to exchange ideas and establish
              communications among researchers working on building generalizable
              world models that describe how the physical world evolves in
              response to interacting agents (e.g. human and robots).
              Large-scale datasets of videos, images, and text hold the key for
              learning generalizable world models that are visually plausible.
              However, distilling useful physical information from such diverse
              unstructured data is challenging and requires careful attention to
              data curation, developing scalable algorithms, and implementing
              suitable training curricula. On the other hand, physics-based
              priors can enable learning plausible scene dynamics but it is
              difficult to scale to complex phenomenon that lack efficient
              solvers or even governing dynamic equations. Developing general
              world models that can simulate complex real-world phenomenon in a
              physically-plausible fashion can unlock enormous opportunities in
              generative modeling and robotics, and would be of wide interest to
              the larger AI community, and we believe this workshop falls at an
              ideal timing given recent significant progress in both
              video-modeling models and physics-based simulation. This workshop
              aims to bring together researchers in machine learning, robotics,
              physics-based simulation, and computer vision broadly aspiring to
              build scalable world models by utilizing internet data,
              simulation, and beyond in myriad ways.
            </div>
          </div>
        </section>

        <section class="section" id="topics">
          <div class="container is-max-desktop content">
            <h2 class="title">Topics of Interest</h2>
            <div class="content has-text-justified">
              Our workshop will focus on topics including but not limited to the
              following:
              <ul>
                <li>
                  <strong
                    >Controllable Video Generation and Generative
                    Simulations.</strong
                  >
                  How can we improve fine-grained control in video generation
                  and integrate it with world models conditioned on low-level
                  actions?
                </li>
                <li>
                  <strong>Incorporating physics priors.</strong> How can we
                  leverage physics prior to empower learned world models with
                  physical realism?
                </li>
                <li>
                  <strong>Dynamic 3D Reconstruction.</strong> How can we
                  generalize 3D reconstruction using web data while preserving
                  scene consistency and controlled motion of dynamic elements?
                </li>
                <li>
                  <strong
                    >Applications to Robotics and Time-Series
                    Prediction.</strong
                  >
                  How can we use generic dataset such as web video and text to
                  build shared world models that can synthesize
                  physically-plausible results for applications such as
                  robotics?
                </li>
                <li>
                  <strong
                    >Special Considerations: Data Curation, Hallucination, and
                    Broader Implications.</strong
                  >
                  How do dataset biases impact learned world models, and how can
                  we mitigate them?
                </li>
              </ul>
            </div>
          </div>
        </section>

        <section class="section" id="call">
          <div class="container is-max-desktop content">
            <h2 class="title">Call for Papers</h2>
            <div class="content has-text-justified">
              <p>
                We invite submissions of original research papers related to
                building physically plausible world models.
              </p>

              <p><strong>Submission Types:</strong></p>
              <ul>
                <li>
                  <strong
                    >Short Papers / Extended Abstracts (max 3 pages)</strong
                  >
                  - For preliminary results, interesting applications, or novel
                  ideas that did not pan out in practice. The top three short
                  papers will be invited for a spotlight talk.
                </li>
                <li>
                  <strong>Full Papers (max 8 pages)</strong> - For original
                  research contributions. Three award candidates will be
                  selected for spotlight talks.
                </li>
              </ul>

              <p><strong>Submission Guidelines:</strong></p>
              <ul>
                <li>
                  Submit your paper via <a href="https://openreview.net/group?id=ICML.cc/2025/Workshop/WM">OpenReview</a>
                </li>
                <li>
                  Please follow the
                  <a href="https://icml.cc/Conferences/2025/AuthorInstructions"
                    >style guidelines of ICML 2025</a
                  >.
                </li>
                <li>
                  Papers are non-archival - we welcome submissions that have
                  been submitted to or accepted by other venues.
                </li>
                <li>
                  Papers already accepted to ICML 2025 will undergo an expedited
                  review process primarily evaluating their relevance to the
                  workshop themes.
                </li>
                <li>
                  All accepted papers will be presented in a poster session
                </li>
                <li>
                  Short papers have a maximum length of 3 pages and appendices
                  are not allowed. Full papers can be up to 8 pages with an
                  unlimited appendix. References do not count toward the page
                  limit and may be as extensive as necessary.
                </li>
              </ul>

              <p><strong>Important Dates:</strong></p>
              <ul>
                <li>Submission Deadline: May 25, 2025</li>
                <li>Notification of Acceptance: June 10, 2025</li>
                <li>Camera ready submission: June 20, 2025</li>
              </ul>
            </div>
          </div>
        </section>

        <section class="section" id="schedule">
          <div class="container is-max-desktop content">
            <h2 class="title">Schedule</h2>
            <div class="content">
              <ul style="list-style-type: none">
                <li>08:50 - 09:00 Welcome/Opening Remarks</li>
                <li>09:00 - 09:30 Invited Talk 1: Agrim Gupta</li>
                <li>09:30 - 10:00 Invited Talk 2: Shuran Song</li>
                <li>10:00 - 10:30 Invited Talk 3: Beomjoon Kim</li>
                <li>10:30 - 11:30 Poster Session: We will encourage folks to make new connections and chat!</li>
                <li>11:30 - 12:15 panel discussion (Shuran Song, Sherry Yang, Yilun Du, Shao-Hua Sun, Chuning Zhu, Wancong Zhang)</li>
                <li>12:15 - 13:30 lunch break</li>
                <li>13:30 - 14:00 Invited Talk 4: Sherry Yang</li>
                <li>14:00 - 14:30 Invited Talk 5: Jiajun Wu</li>
                <li>14:30 - 15:30 Contributed Talks: 10 min. presentations each (one presentation by each best paper)</li>
                <li>15:30 - 16:30 Poster Session: We will encourage folks to make new connections and chat!</li>
                <li>16:30 - 17:00 Invited Talk 6: Hao Su</li>
                <li>17:00 - 17:10 Ending Remarks</li>
              </ul>
            </div>
          </div>
        </section>

        <section class="section" id="speakers">
          <div class="container is-max-desktop content">
            <h2 class="title">Invited Speakers</h2>
            <div class="content">
              <div class="columns is-multiline">
                <div class="column is-4">
                  <div class="card">
                    <div class="card-content has-text-centered">
                      <figure class="image is-128x128 mb-4 mx-auto">
                        <a href="https://sherryy.github.io/">
                          <img
                            class="is-rounded"
                            src="data/images/people/sherry.jpeg"
                            alt="Sherry Yang" />
                        </a>
                      </figure>
                      <p class="title is-5">
                        <a
                          href="https://sherryy.github.io/"
                          style="color: inherit"
                          >Sherry Yang</a
                        >
                      </p>
                      <p class="subtitle is-6">New York University</p>
                    </div>
                  </div>
                </div>

                <div class="column is-4">
                  <div class="card">
                    <div class="card-content has-text-centered">
                      <figure class="image is-128x128 mb-4 mx-auto">
                        <a href="https://web.stanford.edu/~agrim/">
                          <img
                            class="is-rounded"
                            src="data/images/people/agrim.jpg"
                            alt="Agrim Gupta" />
                        </a>
                      </figure>
                      <p class="title is-5">
                        <a
                          href="https://web.stanford.edu/~agrim/"
                          style="color: inherit"
                          >Agrim Gupta</a
                        >
                      </p>
                      <p class="subtitle is-6">Google DeepMind</p>
                    </div>
                  </div>
                </div>

                <div class="column is-4">
                  <div class="card">
                    <div class="card-content has-text-centered">
                      <figure class="image is-128x128 mb-4 mx-auto">
                        <a href="https://shurans.github.io/">
                          <img
                            class="is-rounded"
                            src="data/images/people/shuran.jpg"
                            alt="Shuran Song" />
                        </a>
                      </figure>
                      <p class="title is-5">
                        <a
                          href="https://shurans.github.io/"
                          style="color: inherit"
                          >Shuran Song</a
                        >
                      </p>
                      <p class="subtitle is-6">Stanford University</p>
                    </div>
                  </div>
                </div>

                <div class="column is-4">
                  <div class="card">
                    <div class="card-content has-text-centered">
                      <figure class="image is-128x128 mb-4 mx-auto">
                        <a href="https://cseweb.ucsd.edu/~haosu/">
                          <img
                            class="is-rounded"
                            src="data/images/people/hao.jpg"
                            alt="Hao Su" />
                        </a>
                      </figure>
                      <p class="title is-5">
                        <a
                          href="https://cseweb.ucsd.edu/~haosu/"
                          style="color: inherit"
                          >Hao Su</a
                        >
                      </p>
                      <p class="subtitle is-6">
                        University of California San Diego
                      </p>
                    </div>
                  </div>
                </div>

                <div class="column is-4">
                  <div class="card">
                    <div class="card-content has-text-centered">
                      <figure class="image is-128x128 mb-4 mx-auto">
                        <a href="https://beomjoonkim.github.io/">
                          <img
                            class="is-rounded"
                            src="data/images/people/beom.jpg"
                            alt="Beom Joon Kim" />
                        </a>
                      </figure>
                      <p class="title is-5">
                        <a
                          href="https://beomjoonkim.github.io/"
                          style="color: inherit"
                          >Beom Joon Kim</a
                        >
                      </p>
                      <p class="subtitle is-6">KAIST</p>
                    </div>
                  </div>
                </div>

                <div class="column is-4">
                  <div class="card">
                    <div class="card-content has-text-centered">
                      <figure class="image is-128x128 mb-4 mx-auto">
                        <a href="https://jiajunwu.com/">
                          <img
                            class="is-rounded"
                            src="data/images/people/jiajun.jpg"
                            alt="Jiajun Wu" />
                        </a>
                      </figure>
                      <p class="title is-5">
                        <a
                          href="https://jiajunwu.com/"
                          style="color: inherit"
                          >Jiajun Wu</a
                        >
                      </p>
                      <p class="subtitle is-6">Stanford University</p>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </section>

        <section class="section" id="organizers">
          <div class="container is-max-desktop content">
            <h2 class="title">Organizers</h2>
            <div class="content">
              <div class="columns is-multiline">
                <div class="column is-4">
                  <div class="card">
                    <div class="card-content has-text-centered">
                      <figure class="image is-128x128 mb-4 mx-auto">
                        <a href="https://homangab.github.io/">
                          <img
                            class="is-rounded"
                            src="data/images/people/homanga.jpeg"
                            alt="Homanga Bharadhwaj" />
                        </a>
                      </figure>
                      <p class="title is-5">
                        <a
                          href="https://homangab.github.io/"
                          style="color: inherit"
                          >Homanga Bharadhwaj</a
                        >
                      </p>
                      <p class="subtitle is-6">CMU</p>
                    </div>
                  </div>
                </div>

                <div class="column is-4">
                  <div class="card">
                    <div class="card-content has-text-centered">
                      <figure class="image is-128x128 mb-4 mx-auto">
                        <a href="https://boyuan.space/">
                          <img
                            class="is-rounded"
                            src="data/images/people/boyuan.jpg"
                            alt="Boyuan Chen" />
                        </a>
                      </figure>
                      <p class="title is-5">
                        <a href="https://boyuan.space/" style="color: inherit"
                          >Boyuan Chen</a
                        >
                      </p>
                      <p class="subtitle is-6">MIT</p>
                    </div>
                  </div>
                </div>

                <div class="column is-4">
                  <div class="card">
                    <div class="card-content has-text-centered">
                      <figure class="image is-128x128 mb-4 mx-auto">
                        <a href="https://yilundu.github.io/">
                          <img
                            class="is-rounded"
                            src="data/images/people/yilun.png"
                            alt="Yilun Du" />
                        </a>
                      </figure>
                      <p class="title is-5">
                        <a
                          href="https://yilundu.github.io/"
                          style="color: inherit"
                          >Yilun Du</a
                        >
                      </p>
                      <p class="subtitle is-6">Harvard</p>
                    </div>
                  </div>
                </div>

                <div class="column is-4">
                  <div class="card">
                    <div class="card-content has-text-centered">
                      <figure class="image is-128x128 mb-4 mx-auto">
                        <a href="https://frt03.github.io/">
                          <img
                            class="is-rounded"
                            src="data/images/people/hiroki.jpeg"
                            alt="Hiroki Furuta" />
                        </a>
                      </figure>
                      <p class="title is-5">
                        <a
                          href="https://frt03.github.io/"
                          style="color: inherit"
                          >Hiroki Furuta</a
                        >
                      </p>
                      <p class="subtitle is-6">UTokyo</p>
                    </div>
                  </div>
                </div>

                <div class="column is-4">
                  <div class="card">
                    <div class="card-content has-text-centered">
                      <figure class="image is-128x128 mb-4 mx-auto">
                        <a href="https://ruiqigao.github.io/">
                          <img
                            class="is-rounded"
                            src="data/images/people/ruiqi.png"
                            alt="Ruiqi Gao" />
                        </a>
                      </figure>
                      <p class="title is-5">
                        <a
                          href="https://ruiqigao.github.io/"
                          style="color: inherit"
                          >Ruiqi Gao</a
                        >
                      </p>
                      <p class="subtitle is-6">Google DeepMind</p>
                    </div>
                  </div>
                </div>

                <div class="column is-4">
                  <div class="card">
                    <div class="card-content has-text-centered">
                      <figure class="image is-128x128 mb-4 mx-auto">
                        <a href="https://hkasaei.github.io/">
                          <img
                            class="is-rounded"
                            src="data/images/people/hamidreza.jpeg"
                            alt="Hamidreza Kasaei" />
                        </a>
                      </figure>
                      <p class="title is-5">
                        <a
                          href="https://hkasaei.github.io/"
                          style="color: inherit"
                          >Hamidreza Kasaei</a
                        >
                      </p>
                      <p class="subtitle is-6">University of Groningen</p>
                    </div>
                  </div>
                </div>

                <div class="column is-4">
                  <div class="card">
                    <div class="card-content has-text-centered">
                      <figure class="image is-128x128 mb-4 mx-auto">
                        <a href="https://kirmani.ai/">
                          <img
                            class="is-rounded"
                            src="data/images/people/sean.jpg"
                            alt="Sean Kirmani" />
                        </a>
                      </figure>
                      <p class="title is-5">
                        <a href="https://kirmani.ai/" style="color: inherit"
                          >Sean Kirmani</a
                        >
                      </p>
                      <p class="subtitle is-6">Google DeepMind</p>
                    </div>
                  </div>
                </div>

                <div class="column is-4">
                  <div class="card">
                    <div class="card-content has-text-centered">
                      <figure class="image is-128x128 mb-4 mx-auto">
                        <a href="https://kuanghuei.github.io/">
                          <img
                            class="is-rounded"
                            src="data/images/people/kuang-huei.png"
                            alt="Kuang-Huei Lee" />
                        </a>
                      </figure>
                      <p class="title is-5">
                        <a
                          href="https://kuanghuei.github.io/"
                          style="color: inherit"
                          >Kuang-Huei Lee</a
                        >
                      </p>
                      <p class="subtitle is-6">Google DeepMind</p>
                    </div>
                  </div>
                </div>

                <div class="column is-4">
                  <div class="card">
                    <div class="card-content has-text-centered">
                      <figure class="image is-128x128 mb-4 mx-auto">
                        <a href="https://ruoshiliu.github.io/">
                          <img
                            class="is-rounded"
                            src="data/images/people/ruoshi.jpg"
                            alt="Ruoshi Liu" />
                        </a>
                      </figure>
                      <p class="title is-5">
                        <a
                          href="https://ruoshiliu.github.io/"
                          style="color: inherit"
                          >Ruoshi Liu</a
                        >
                      </p>
                      <p class="subtitle is-6">Columbia</p>
                    </div>
                  </div>
                </div>

                <div class="column is-4">
                  <div class="card">
                    <div class="card-content has-text-centered">
                      <figure class="image is-128x128 mb-4 mx-auto">
                        <a href="https://lzylucy.github.io/">
                          <img
                            class="is-rounded"
                            src="data/images/people/zeyi.jpg"
                            alt="Zeyi Liu" />
                        </a>
                      </figure>
                      <p class="title is-5">
                        <a
                          href="https://lzylucy.github.io/"
                          style="color: inherit"
                          >Zeyi Liu</a
                        >
                      </p>
                      <p class="subtitle is-6">Stanford</p>
                    </div>
                  </div>
                </div>

                <div class="column is-4">
                  <div class="card">
                    <div class="card-content has-text-centered">
                      <figure class="image is-128x128 mb-4 mx-auto">
                        <a href="https://profiles.stanford.edu/fei-fei-li">
                          <img
                            class="is-rounded"
                            src="data/images/people/feifei.jpg"
                            alt="Fei-Fei Li" />
                        </a>
                      </figure>
                      <p class="title is-5">
                        <a
                          href="https://profiles.stanford.edu/fei-fei-li"
                          style="color: inherit"
                          >Fei-Fei Li</a
                        >
                      </p>
                      <p class="subtitle is-6">Stanford</p>
                    </div>
                  </div>
                </div>

                <div class="column is-4">
                  <div class="card">
                    <div class="card-content has-text-centered">
                      <figure class="image is-128x128 mb-4 mx-auto">
                        <a href="https://profiles.stanford.edu/fei-fei-li">
                          <img
                            class="is-rounded"
                            src="data/images/people/carl.jpeg"
                            alt="Carl Vondrick" />
                        </a>
                      </figure>
                      <p class="title is-5">
                        <a
                          href="https://profiles.stanford.edu/fei-fei-li"
                          style="color: inherit"
                          >Carl Vondrick</a
                        >
                      </p>
                      <p class="subtitle is-6">Columbia</p>
                    </div>
                  </div>
                </div>

                <div class="column is-4">
                  <div class="card">
                    <div class="card-content has-text-centered">
                      <figure class="image is-128x128 mb-4 mx-auto">
                        <a href="https://wenhaoyu.weebly.com/">
                          <img
                            class="is-rounded"
                            src="data/images/people/wenhao.png"
                            alt="Wenhao Yu" />
                        </a>
                      </figure>
                      <p class="title is-5">
                        <a
                          href="https://wenhaoyu.weebly.com/"
                          style="color: inherit"
                          >Wenhao Yu</a
                        >
                      </p>
                      <p class="subtitle is-6">Google DeepMind</p>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </section>
      </div>
    </section>
    <section class="section" id="best-papers">
      <div class="container is-max-desktop content">
        <h2 class="title">Best Papers</h2>
        <ul>
          <li><b><a href="https://openreview.net/forum?id=g6wi263Szj">Implicit State Estimation via Video Replanning</a></b><br><small>Po-Chen Ko, Jiayuan Mao, Yu-Hsiang Fu, Hsien-Jeng Yeh, Chu-Rong Chen, Wei-Chiu Ma, Yilun Du, Shao-Hua Sun</small></li>
          <li><b><a href="https://openreview.net/forum?id=md8obsBO5b">Learning from Reward-Free Offline Data: A Case for Planning with Latent Dynamics Models</a></b><br><small>Vlad Sobal, Wancong Zhang, Kyunghyun Cho, Randall Balestriero, Tim G. J. Rudner, Yann LeCun</small></li>
          <li><b><a href="https://openreview.net/forum?id=5qsYjl7QXC">Enhancing Long Video Generation Consistency without Tuning: Time-Frequency Analysis, Prompt Alignment, and Theory</a></b><br><small>Xingyao Li, Fengzhuo Zhang, Jiachun Pan, Yunlong Hou, Vincent Y. F. Tan, Zhuoran Yang</small></li>
          <li><b><a href="https://openreview.net/forum?id=y5w91PODrA">VideoPhy-2: A Challenging Action-Centric Physical Commonsense Evaluation in Video Generation</a></b><br><small>Hritik Bansal, Clark Peng, Yonatan Bitton, Roman Goldenberg, Aditya Grover, Kai-Wei Chang</small></li>
          <li><b><a href="https://openreview.net/forum?id=J53Wwra67w">Unified World Models: Coupling Video and Action Diffusion for Pretraining on Large Robotic Datasets</a></b><br><small>Chuning Zhu, Raymond Yu, Siyuan Feng, Benjamin Burchfiel, Paarth Shah, Abhishek Gupta</small></li>
          <li><b><a href="https://openreview.net/forum?id=yyW3mnTTwK">EmbodiedScene: Towards Automated Generation of Diverse and Realistic Scenes for Embodied AI</a></b><br><small>Jinbin Qiao, Pengyi Li, Peilong Han, YAN ZHENG, Jianye HAO</small></li>
        </ul>
      </div>
    </section>
    <section class="section" id="accepted-papers">
      <div class="container is-max-desktop content">
        <h2 class="title">Accepted Papers</h2>
        <ul>
          <li><b><a href="https://openreview.net/forum?id=XPn4UwfpU3">SP: Learning Physics from Sparse Observations — Three Pitfalls of PDE-Constrained Diffusion Models</a></b><br><small>Ruichen Xu, Haochun Wang, Georgios Kementzidis, Chenhao Si, Yuefan Deng</small></li>
          <li><b><a href="https://openreview.net/forum?id=sPywxoM43G">Object-Centric Latent Action Learning</a></b><br><small>Albina Klepach, Alexander Nikulin, Ilya Zisman, Denis Tarasov, Alexander Derevyagin, Andrei Polubarov, Lyubaykin Nikita, Igor Kiselev, Vladislav Kurenkov</small></li>
          <li><b><a href="https://openreview.net/forum?id=XDTUHAfGL1">SP: Continuous Autoregressive Generation with Mixture of Gaussians</a></b><br><small>Alex Quach, Tsun-Hsuan Wang, Ramin Hasani, Mathias Lechner, Alexander Amini</small></li>
          <li><b><a href="https://openreview.net/forum?id=17DIBG2Vx5">Adapting Vision-Language Models for Evaluating World Models</a></b><br><small>Mariya Hendriksen, Tabish Rashid, David Bignell, Raluca Stevenson, Abdelhak Lemkhenter, Katja Hofmann, Sam Devlin, Sarah Parisot</small></li>
          <li><b><a href="https://openreview.net/forum?id=ENAycZapM2">Humanoid World Models: Open World Foundation Models for Humanoid Robotics</a></b><br><small>Muhammad Qasim Ali, Aditya Sridhar, Alexander Wong, Mohammad Al-Sharman</small></li>
          <li><b><a href="https://openreview.net/forum?id=VHO92hiDWu">Can Image-To-Video Models Simulate Pedestrian Dynamics?</a></b><br><small>Aaron Appelle, Jerome P. Lynch</small></li>
          <li><b><a href="https://openreview.net/forum?id=8mxv50eNJU">SP- PhysicsNeRF: Physics-Guided 3D Reconstruction from Sparse Views</a></b><br><small>Mohamed Rayan Barhdadi, HASAN KURBAN, Hussein Alnuweiri</small></li>
          <li><b><a href="https://openreview.net/forum?id=lYE7z51xiW">SP: JEPA-WMs: On Planning with Joint-Embedding Predictive World Models</a></b><br><small>Basile Terver, Yann LeCun, Adrien Bardes</small></li>
          <li><b><a href="https://openreview.net/forum?id=kWbxSUEj6E">Eyes of the DINO: Learning Physical World Models from Uncurated Web Videos</a></b><br><small>Federico Baldassarre, Marc Szafraniec, Vasil Khalidov, Maximilian Seitzer, Piotr Bojanowski</small></li>
          <li><b><a href="https://openreview.net/forum?id=2lWFLdg0vp">GRIM: Task-Oriented Grasping with Conditioning on Generative Examples</a></b><br><small>Shailesh, Alok Raj, Nayan Kumar, Priya Shukla, Andrew Melnik, Michael Beetz, Gora Chand Nandi</small></li>
          <li><b><a href="https://openreview.net/forum?id=MNj9QuMFCM">Direct Robot Configuration Space Construction using Convolutional Encoder-Decoders</a></b><br><small>Christopher Benka, Judah Goldfeder, Carl Gross, Riya Gupta, Hod Lipson</small></li>
          <li><b><a href="https://openreview.net/forum?id=GzP9rJ1mkG">TrajEvo: Designing Trajectory Prediction Heuristics via LLM-driven Evolution</a></b><br><small>Zhikai Zhao, Chuanbo Hua, Federico Berto, Kanghoon Lee, Zihan Ma, Jiachen Li, Jinkyoo Park</small></li>
          <li><b><a href="https://openreview.net/forum?id=l4y0NZBue3">Video Self-Distillation for Single-Image Encoders: A Step Toward Physically Plausible Perception</a></b><br><small>Marcel Simon, Tae-Ho Kim, Seul-Ki Yeom</small></li>
          <li><b><a href="https://openreview.net/forum?id=XbjHUtYZya">EquiReg: Symmetry-Driven Regularization for Physically Grounded Diffusion-based Inverse Solvers</a></b><br><small>Bahareh Tolooshams, Aditi Chandrashekar, Rayhan Zirvi, Abbas Mammadov, Jiachen Yao, Chuwei Wang, Anima Anandkumar</small></li>
          <li><b><a href="https://openreview.net/forum?id=Tl6A59CdbF">Self Forcing: Bridging the Train-Test Gap in Autoregressive Video Diffusion</a></b><br><small>Xun Huang, Zhengqi Li, Guande He, Mingyuan Zhou, Eli Shechtman</small></li>
          <li><b><a href="https://openreview.net/forum?id=mIApTr3iRm">DAWM: Diffusion Action World Models for Offline Reinforcement Learning via Action-Inferred Transitions</a></b><br><small>Zongyue Li, Xiao Han, Yusong Li, Niklas Alexander Strauß, Matthias Schubert</small></li>
          <li><b><a href="https://openreview.net/forum?id=bFN9zZT720">World4Omni: A Zero-Shot Framework from Image Generation World Model to Robotic Manipulation</a></b><br><small>Haonan Chen, Bangjun Wang, Jingxiang Guo, Tianrui Zhang, Yiwen Hou, Xuchuan Huang, Chenrui Tie, Lin Shao</small></li>
          <li><b><a href="https://openreview.net/forum?id=7Udx16p9Rz">Learning Skill Abstraction from Action-Free Videos via Optical Flow</a></b><br><small>Hung-Chieh Fang, Kuo-Han Hung, Chu-Rong Chen, Po-Jung Chou, Chun-Kai Yang, Po-Chen Ko, Yu-Chiang Frank Wang, Yueh-Hua Wu, Min-Hung Chen, Shao-Hua Sun</small></li>
          <li><b><a href="https://openreview.net/forum?id=fnxeang62m">Neural Modular World Model</a></b><br><small>Minghao Guo, Zhiyang Dou, Chong Zeng, Wojciech Matusik</small></li>
          <li><b><a href="https://openreview.net/forum?id=Akxfidh6VI">A Comprehensive Evaluation of Physical Realism in Text-to-Video Models</a></b><br><small>Jing Gu, Xian Liu, Yu Zeng, Ashwin Nagarajan, Fangrui Zhu, Daniel Hong, Yue Fan, Qianqi Yan, Kaiwen Zhou, Ming-Yu Liu, Xin Eric Wang</small></li>
          <li><b><a href="https://openreview.net/forum?id=xWyZVgueaE">Revisiting Multi-Agent World Modeling from a Diffusion-Inspired Perspective</a></b><br><small>Yang Zhang, Xinran Li, Delin Qu, Jianing Ye, Chongjie Zhang, Xiu Li, Chenjia Bai</small></li>
          <li><b><a href="https://openreview.net/forum?id=bDkI0mGWIe">Bidding for Influence: Auction-Driven Diffusion Image Generation</a></b><br><small>Lillian Sun, Henry Huang, Fucheng Warren Zhu, Giannis Daras, Constantinos Costis Daskalakis</small></li>
          <li><b><a href="https://openreview.net/forum?id=3686yBriW8">CCC: Enhancing Video Generation via Structured MLLM Feedback</a></b><br><small>Jing Gu, Ashwin Nagarajan, Tejas Polu, Kaizhi Zheng, Ruijian Zha, Jie Yang, Xin Eric Wang</small></li>
          <li><b><a href="https://openreview.net/forum?id=x7efU2MG2H">Fostering Video Reasoning via Next-Event Prediction</a></b><br><small>Haonan Wang, Hongfu Liu, Xiangyan Liu, Chao Du, Kenji Kawaguchi, Ye Wang, Tianyu Pang</small></li>
          <li><b><a href="https://openreview.net/forum?id=KxFVJoWSpo">RobotSmith: Generative Robotic Tool Design for Acquisition of Complex Manipulation Skills</a></b><br><small>Chunru Lin, Haotian Yuan, Yian Wang, Xiaowen Qiu, Tsun-Hsuan Wang, Minghao Guo, Bohan Wang, Yashraj Narang, Dieter Fox, Chuang Gan</small></li>
          <li><b><a href="https://openreview.net/forum?id=GG6crEUcTI">PlaySlot: Learning Inverse Latent Dynamics for Controllable Object-Centric Video Prediction and Planning</a></b><br><small>Angel Villar-Corrales, Sven Behnke</small></li>
          <li><b><a href="https://openreview.net/forum?id=PBwoli2Ab7">Probing Perceptual Constancy in Large Vision Language Models</a></b><br><small>Haoran Sun, Suyang Yu, Yijiang Li, Qingying Gao, Haiyun Lyu, Hokin Deng, Dezhi Luo</small></li>
          <li><b><a href="https://openreview.net/forum?id=LWaImGySjc">Learning an Implicit Physics Model for Image-Based Fluid Simulation</a></b><br><small>Emily Yue-ting Jia, Jiageng Mao, Zhiyuan Gao, Yajie Zhao, Yue Wang</small></li>
          <li><b><a href="https://openreview.net/forum?id=UsBSksAMhc">Seeing the Wind from a Falling Leaf</a></b><br><small>Zhiyuan Gao, Jiageng Mao, Hong-Xing Yu, Haozhe Lou, Emily Yue-ting Jia, Jernej Barbic, Jiajun Wu, Yue Wang</small></li>
          <li><b><a href="https://openreview.net/forum?id=oBPOeWfvZr">PhyRecon: Physically Plausible Neural Scene Reconstruction</a></b><br><small>Junfeng Ni, Yixin Chen, Bohan Jing, Nan Jiang, Bin Wang, Bo Dai, Puhao Li, Yixin Zhu, Song-Chun Zhu, Siyuan Huang</small></li>
          <li><b><a href="https://openreview.net/forum?id=kncC8xwggZ">SP: PhysTwin: Physics-Informed Reconstruction and Simulation of Deformable Objects from Video</a></b><br><small>Hanxiao Jiang, Hao-Yu Hsu, Kaifeng Zhang, Hsin-Ni Yu, Shenlong Wang, Yunzhu Li</small></li>
        </ul>
      </div>
    </section>
  </body>
</html>
